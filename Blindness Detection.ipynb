{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.applications import VGG16\n",
    "from keras import Sequential\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense,Reshape,Flatten,Dropout,GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D ,Input\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as k\n",
    "from keras import optimizers\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "import os\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/aptos2019-blindness-detection/train.csv')\n",
    "tset_data = pd.read_csv('/kaggle/input/aptos2019-blindness-detection/test.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_from_gray(img, tol=7):\n",
    "    \"\"\"\n",
    "    Applies masks to the orignal image and \n",
    "    returns the a preprocessed image with \n",
    "    3 channels\n",
    "    \"\"\"\n",
    "    # If for some reason we only have two channels\n",
    "    if img.ndim == 2:\n",
    "        mask = img > tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    # If we have a normal RGB images\n",
    "    elif img.ndim == 3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img > tol\n",
    "        \n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "            return img # return original image\n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "        return img\n",
    "\n",
    "def preprocess_image(path, sigmaX=10):\n",
    "    \"\"\"\n",
    "    The whole preprocessing pipeline:\n",
    "    1. Read in image\n",
    "    2. Apply masks\n",
    "    3. Resize image to desired size\n",
    "    4. Add Gaussian noise to increase Robustness\n",
    "    \"\"\"\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = crop_image_from_gray(image)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = cv2.addWeighted (image,4, cv2.GaussianBlur(image, (0,0) ,sigmaX), -4, 128)\n",
    "    return image\n",
    "\n",
    "\n",
    "N = train_data.shape[0]\n",
    "x = np.empty((N,224,224,3),dtype=np.uint8)\n",
    "for index,image_id in enumerate(tqdm(train_data['id_code'])):\n",
    "    x[index,:,:,:]  = preprocess_image('/kaggle/input/aptos2019-blindness-detection/train_images/'+image_id+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np_utils.to_categorical(train_data.diagnosis)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.15,shuffle=False,random_state=False)\n",
    "\n",
    "\n",
    "\n",
    "data_gen  = ImageDataGenerator(rotation_range=15,\n",
    "                     rescale=1./255,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   shear_range=0.01,\n",
    "                                   zoom_range=[0.9, 1.25],\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   fill_mode='reflect',\n",
    "                                   data_format='channels_last',\n",
    "                                   brightness_range=[0.5, 1.5])\n",
    "\n",
    "train_datagen = data_gen.flow(x_train,y_train,batch_size=32)\n",
    "valid_datagen = data_gen.flow(x_test,y_test,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(weights=None,input_shape=(224,224,3),include_top=False,classes=5)\n",
    "#vgg.load_weights('/kaggle/input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "model = Sequential()\n",
    "for layer in vgg.layers:\n",
    "    model.add(layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(540,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dropout(0.45))\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "    \n",
    "callback = ModelCheckpoint(\"best_weights.h5\", monitor='acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto',\n",
    "                             period=1)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "# Reducing the Learning Rate if result is not improving. \n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.1, mode='auto',\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam(1e-4),\n",
    "              loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit_generator(generator=train_datagen,\n",
    "                    steps_per_epoch=98,\n",
    "                    validation_data=valid_datagen,\n",
    "                    validation_steps=18,\n",
    "                    epochs=30,\n",
    "                    callbacks = [callback,early_stop,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_weights.h5')\n",
    "test_csv = pd.read_csv(\"/kaggle/input/aptos2019-blindness-detection/test.csv\")\n",
    "predicted_csv = pd.DataFrame(columns=[\"id_code\", \"diagnosis\"])\n",
    "\n",
    "N = test_csv.shape[0]\n",
    "x_test = np.empty((N,224,224,3),dtype=np.uint8)\n",
    "for index,image_id in enumerate(tqdm(test_csv['id_code'])):\n",
    "    x_test[index,:,:,:]  = preprocess_image('/kaggle/input/aptos2019-blindness-detection/test_images/'+image_id+'.png')\n",
    "    img = x_test[index]\n",
    "    img = np.expand_dims(img, 0)\n",
    "    prediction = int(np.argmax(model.predict(img)))\n",
    "    predicted_csv = predicted_csv.append(\n",
    "        {'id_code':image_id ,\"diagnosis\": prediction}, ignore_index=True)\n",
    "\n",
    "with open(\"submission.csv\", \"w\") as f:\n",
    "    f.write(predicted_csv.to_csv(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
